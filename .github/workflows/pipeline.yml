name: Daily Intelligence Pipeline

on:
  schedule:
    # Inverno (Gen-Mar, Nov-Dic): 07:00 UTC = 08:00 CET
    - cron: "0 7 * 1,2,3,11,12 *"
    # Estate (Apr-Ott): 06:00 UTC = 08:00 CEST
    - cron: "0 6 * 4,5,6,7,8,9,10 *"
  workflow_dispatch: # trigger manuale dalla tab Actions

permissions:
  contents: read

jobs:
  pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 360 # 6 ore max (il NLP da solo può durare 90+ minuti)

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"

      - name: Cache HuggingFace models
        uses: actions/cache@v4
        with:
          path: ~/.cache/huggingface/hub
          key: hf-models-v1
          restore-keys: hf-models-

      - name: Install dependencies
        run: |
          pip install -r requirements-prod.txt
          python -m spacy download xx_ent_wiki_sm

      - name: Download sentence-transformers models
        run: |
          python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')"
          python -c "from sentence_transformers import CrossEncoder; CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"

      - name: Setup SSH tunnel to Hetzner DB
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.VPS_SSH_KEY }}" > ~/.ssh/id_ed25519
          chmod 600 ~/.ssh/id_ed25519
          # Fingerprint del server noto (anti-MITM, vedi README per come ottenere VPS_KNOWN_HOSTS)
          echo "${{ secrets.VPS_KNOWN_HOSTS }}" >> ~/.ssh/known_hosts
          # Tunnel: runner:5432 → Hetzner 127.0.0.1:5432 (postgres Docker su loopback)
          ssh -fN -L 5432:127.0.0.1:5432 deploy@${{ secrets.VPS_HOST }}
          sleep 3

      - name: Run pipeline
        env:
          DATABASE_URL: postgresql://${{ secrets.POSTGRES_USER }}:${{ secrets.POSTGRES_PASSWORD }}@localhost:5432/intelligence_ita
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          FRED_API_KEY: ${{ secrets.FRED_API_KEY }}
          FMP_API_KEY: ${{ secrets.FMP_API_KEY }}
          PYTHONPATH: ${{ github.workspace }}
          REPORT_OUTPUT_DIR: ./reports
          DATA_DIR: ./data
          ENVIRONMENT: production
          PIPELINE_NOTIFY_ON_SUCCESS: "false"
          PIPELINE_NOTIFY_ON_FAILURE: "false"
        run: |
          mkdir -p logs reports data
          python scripts/daily_pipeline.py

      - name: Upload logs as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-logs-${{ github.run_id }}
          path: logs/
          retention-days: 30
